# Unified Security Event Pipeline for Enterprise Threat Detection
**CS 4265: Big Data Analytics â€” Milestone 1 Submission**

## ğŸ“ Overview
This project implements a scalable distributed data pipeline designed to ingest, process, and enrich massive enterprise-scale security telemetry. By correlating the **LANL Unified Host and Network Dataset** (~700M events) with real-time threat intelligence feeds (URLHaus), the system enables the detection of sophisticated cyber threats such as lateral movement and compromised credentials.

## ğŸ›  The Big Data Stack
The architecture is designed to handle the **Volume, Variety, and Velocity** of security logs by leveraging a layered distributed system:

| Layer | Technology | Core Big Data Concept |
| :--- | :--- | :--- |
| **Storage** | HDFS | Distributed Block Storage (128MB) & Replication Factor 3 |
| **Processing** | Apache Spark on YARN | Parallel DAG Execution, Map-Shuffle-Reduce Optimization |
| **Data Store** | Apache HBase | Wide-column Model, LSM-Trees, & Column Families |
| **Syntax** | Apache Parquet | Columnar Storage with Snappy Compression |
| **Querying** | Spark SQL / DataFrames | Distributed Execution & Partition-aware Querying |

## ğŸ“‚ Project Structure
```text
/
â”œâ”€â”€ data/               # Metadata and small threat feed samples (Local)
â”œâ”€â”€ docs/               # Architecture diagrams and Milestone PDF reports
â”œâ”€â”€ notebooks/          # Jupyter notebooks for threat hunting and visualization
â”œâ”€â”€ src/                # Core pipeline source code
â”‚   â”œâ”€â”€ ingestion/      # PySpark jobs for moving raw logs into HDFS
â”‚   â”œâ”€â”€ processing/     # Normalization, Broadcast Joins, and Enrichment logic
â”‚   â””â”€â”€ stores/         # HBase schema definitions and write operations
â”œâ”€â”€ .gitignore          # Excludes large logs and temporary Spark files
â””â”€â”€ README.md           # Project overview and documentation
